<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />



<meta name="date" content="2023-04-14" />

<title>Talent Management Solutions For Frito Lay</title>

<script src="site_libs/header-attrs-2.20/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/yeti.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">My Website</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-heart"></span>
     
    About Me
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="fa fa-file"></span>
     
    Projects
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="Rscript.html">FritoLay-Attrition-Analysis</a>
    </li>
    <li>
      <a href="BudweiserEDA1.html">Budweiser-EDA</a>
    </li>
    <li>
      <a href="PizzaBI-Project.html">PizzaBI-Project</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Talent Management Solutions For Frito
Lay</h1>
<h4 class="date">2023-04-14</h4>

</div>

<div id="TOC">
<ul>
<li><a href="#introduction" id="toc-introduction">Introduction</a></li>
<li><a href="#prepration" id="toc-prepration">Prepration</a></li>
<li><a href="#data-preparation" id="toc-data-preparation">Data
Preparation</a></li>
<li><a href="#data-prepration-step-2"
id="toc-data-prepration-step-2">Data Prepration Step 2</a></li>
<li><a href="#exploratory-data-analysis"
id="toc-exploratory-data-analysis">Exploratory Data Analysis</a></li>
<li><a href="#fitting-the-model-knn"
id="toc-fitting-the-model-knn">Fitting the model (KNN)</a></li>
<li><a href="#model-selection-navie-bays"
id="toc-model-selection-navie-bays">Model Selection (Navie
Bays)</a></li>
<li><a href="#model-selection-linear-regression"
id="toc-model-selection-linear-regression">Model Selection (Linear
Regression)</a></li>
<li><a href="#ensemble-models" id="toc-ensemble-models">Ensemble
Models</a></li>
<li><a href="#predict-attrition" id="toc-predict-attrition">Predict
(Attrition)</a></li>
<li><a href="#predict-monthlyincome"
id="toc-predict-monthlyincome">Predict (MonthlyIncome)</a></li>
<li><a href="#conclusion-recommendation"
id="toc-conclusion-recommendation">Conclusion &amp;
Recommendation</a></li>
</ul>
</div>

<div id="introduction" class="section level2">
<h2>Introduction</h2>
<ul>
<li><p>Welcome to this Attrition analysis, we are acting as a talent
management analytics company for Fortune 100 company Frito Lay to
predict employee turnover. As our lead data scientist, I will analyze
existing employee data to identify the top three factors contributing to
attrition and job role-specific trends. The analysis will involve robust
experimentation and appropriate visualization in R, with a predictive
model built to forecast employee turnover.</p></li>
<li><p>We have also developed algorithm simulator App for easier
digestion of future data set into streamlined process. Users will be
able to voluntarily upload the data set and choose the corresponding ML
model to find out the best fitting results for future attrition
analysis. The R shiny app is made available below.</p></li>
<li><p><a href="https://haitieliu.shinyapps.io/Project2/">Use Rshiny
App</a></p></li>
</ul>
<p><img
src="https://upload.wikimedia.org/wikipedia/commons/thumb/6/67/Fritolay_company_logo.svg/1280px-Fritolay_company_logo.svg.png" /></p>
</div>
<div id="prepration" class="section level2">
<h2>Prepration</h2>
<p>loading needed packages</p>
<pre class="r"><code>###loading libraries
library(tidyverse)
library(dplyr)
library(ggplot2)
library(plotly)
library(caret)
library(class)
library(e1071)
library(GGally)
library(ROCit)</code></pre>
</div>
<div id="data-preparation" class="section level2">
<h2>Data Preparation</h2>
<ul>
<li><p>Loading correct data set into R</p></li>
<li><p>Looking for Na Values and outlier</p></li>
</ul>
<pre class="r"><code>#load data set
data1=read.csv(file = &quot;CaseStudy2-data.csv&quot;)
#sum(is.na(data1))
#Changing Col order
data1=data1[c(3,1,2,4:36)]
#Checking the imbalance of the data set
#table(data1$Attrition)
# 730/140 = 5:1
# Attrition is roughly 0.2/1</code></pre>
</div>
<div id="data-prepration-step-2" class="section level2">
<h2>Data Prepration Step 2</h2>
<ul>
<li><p>Factorize data set for easier interpretation and
analysis</p></li>
<li><p>For categorical variables, taking the approach to factorize
first</p></li>
<li><p>Split the data into people who left and people who
stayed</p></li>
<li><p>Then conducting T-test against all other columns</p></li>
<li><p>Finding out the least P value to determine its
significance</p></li>
</ul>
<pre class="r"><code>#factorize the data and scale it. Adding column response assign it with Yes and No
data_scaled = 
  data1 %&gt;%
  mutate_if(is.character, as.factor) %&gt;%
  mutate_if(is.factor, ~as.integer(factor(.)) - 1) 


preproc=preProcess(data_scaled)
data_scaled=predict(preproc,data_scaled)  
data_scaled=data_scaled%&gt;%      
      mutate(response = ifelse(as.numeric(factor(data1[,&quot;Attrition&quot;])) == 1, &quot;Yes&quot;, &quot;No&quot;))

#Conducting T-Test on all other columns
Ttest=data_scaled%&gt;%
      select(-{&quot;Attrition&quot;}) %&gt;%
      select_if(~ !all(is.na(.)))%&gt;%
      pivot_longer(cols = -response, names_to = &quot;variable&quot;, values_to = &quot;value&quot;) %&gt;%
      group_by(variable) %&gt;%
      summarize(pvalue = sprintf(&quot;%.15f&quot;, t.test(value ~ response)$p.value))%&gt;%
      filter(pvalue &lt;= 0.05)

dataX =  data_scaled %&gt;%
  select(Ttest$variable, Attrition)
    
    if (!is.factor(dataX[[&quot;Attrition&quot;]])) {
      dataX[[&quot;Attrition&quot;]] = as.numeric(factor(dataX[[&quot;Attrition&quot;]]))-1
    }

data2=dataX
data3=data2</code></pre>
</div>
<div id="exploratory-data-analysis" class="section level2">
<h2>Exploratory Data Analysis</h2>
<ul>
<li><p>Dive deep into Job sanctification</p></li>
<li><p>What are the top three factors leading people to leave</p></li>
<li><p>Intricate relationship between each factor to another</p></li>
<li><p>Mechanics to prevent higher attrition in the future</p></li>
</ul>
<pre class="r"><code>#EDA


data1_summary &lt;- data1 %&gt;%
  group_by(JobRole) %&gt;%
  summarize(mean_JobSatisfaction = mean(as.numeric(JobSatisfaction)))

ggplot(data1_summary, aes(x = JobRole, y = mean_JobSatisfaction, fill = JobRole)) +
  geom_bar(stat = &quot;identity&quot;) +
  labs(title = &quot;Job Satisfaction by Job Role&quot;,
       subtitle = &quot;Comparison of Job Satisfaction Levels by Job Role&quot;,
       x = &quot;Job Role&quot;,
       y = &quot;Job Satisfaction&quot;,
       fill = &quot;Job Role&quot;) +
  ggthemes::theme_clean() +
  theme(axis.text.x = element_text(size = 10, angle = 45, hjust = 1),
        panel.spacing.x = unit(2, &quot;cm&quot;)) +
  guides(fill = FALSE)</code></pre>
<p><img src="Rscript_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<ul>
<li>Comment: we can see that the most satisfied job roles are sales
representative and research scientist</li>
</ul>
<p><br /> <br /></p>
<pre class="r"><code># plot Job Satisfaction by MaritalStatus
data1_summary2 &lt;- data1 %&gt;%
  group_by(MaritalStatus) %&gt;%
  summarize(mean_JobSatisfaction = mean(as.numeric(JobSatisfaction)))

ggplot(data1_summary2, aes(x = MaritalStatus, y = mean_JobSatisfaction, fill = MaritalStatus)) + 
  geom_bar(stat = &quot;identity&quot;) +
  labs(title = &quot;Job Satisfaction by Marital Status&quot;,
       subtitle = &quot;Comparison of Job Satisfaction Levels by Marital Status&quot;,
       x = &quot;Marital Status&quot;,
       y = &quot;Mean Job Satisfaction&quot;,
       fill = &quot;Marital Status&quot;) +
  ggthemes::theme_clean() +
  theme(axis.text.x = element_text(size = 10, angle = 45, hjust = 1),
        panel.spacing.x = unit(2, &quot;cm&quot;)) +
  guides(fill = FALSE)</code></pre>
<p><img src="Rscript_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<ul>
<li>Comment: single workers are likely to be more satisfied with their
current role <br /> <br /></li>
</ul>
<pre class="r"><code>data1_summary2 &lt;- data1 %&gt;%
  group_by(JobSatisfaction) %&gt;%
  summarize(mean_JobSatisfaction = mean(as.numeric(DistanceFromHome)))

ggplot(data1_summary2, aes(x = JobSatisfaction, y = mean_JobSatisfaction, fill = JobSatisfaction)) + 
  geom_bar(stat = &quot;identity&quot;) +
  labs(title = &quot;Job Satisfaction by DistanceFromHome&quot;,
       subtitle = &quot;Comparison of Job Satisfaction Levels by DistanceFromHome&quot;,
       x = &quot;DistanceFromHome&quot;,
       y = &quot;Job Satisfaction&quot;,
       fill = &quot;DistanceFromHome&quot;) +
  ggthemes::theme_clean() +
  theme(axis.text.x = element_text(size = 10, angle = 45, hjust = 1),
        panel.spacing.x = unit(2, &quot;cm&quot;)) +
  guides(fill = FALSE)</code></pre>
<p><img src="Rscript_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<ul>
<li>Comment: the more distant you are from work the less satisfied you
are <br /> <br /></li>
</ul>
<pre class="r"><code>  ggplot(data2, aes(x = Attrition, y = MonthlyIncome)) +
    geom_point(color = &quot;darkblue&quot;, size = 3, alpha = 0.5) +
    labs(title = &quot;Attrition vs Monthly Income&quot;,
         subtitle = &quot;Scatterplot of Attrition with Monthly Income&quot;,
         x = &quot;Attrition&quot;,
         y = &quot;Monthly Income&quot;) +
    ggthemes::theme_clean() +
    geom_smooth(method = &quot;lm&quot;, se = FALSE, color = &quot;red&quot;, size = 1.2) +
    theme(plot.title = element_text(size = 20, face = &quot;bold&quot;, hjust = 0.5),
          plot.subtitle = element_text(size = 16, hjust = 0.5),
          axis.title = element_text(size = 14),
          axis.text = element_text(size = 12),
          legend.position = &quot;none&quot;)</code></pre>
<p><img src="Rscript_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<ul>
<li>Comment: monthly income is negatively correlated with attrition,
increase monthly income is liley to reduce attrition rate <br />
<br /></li>
</ul>
<pre class="r"><code>  ggplot(data2, aes(x = Attrition, y = OverTime)) +
    geom_point(color = &quot;#c44e52&quot;) +
    labs(title = &quot;Attrition vs OverTime&quot;,
         subtitle = &quot;Scatterplot of Attrition with OverTime&quot;,
         x = &quot;Attrition&quot;,
         y = &quot;OverTime&quot;) +
    geom_smooth(method = &quot;lm&quot;, se = FALSE, color = &quot;darkblue&quot;, size = 1.2) +
    theme_bw()</code></pre>
<p><img src="Rscript_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<ul>
<li>Comment: attrition seems to be positively correlated with attrition,
more overtime could mean more attrition <br /> <br /></li>
</ul>
<pre class="r"><code>  # Plot a scatterplot of TotalWorkingYears by Attrition
  ggplot(data2, aes(x = Attrition, y = TotalWorkingYears)) +
    geom_point(color = &quot;#3c78d8&quot;) +
    labs(title = &quot;Attrition vs Total Working Years&quot;,
         subtitle = &quot;Scatterplot of Attrition with Total Working Years&quot;,
         x = &quot;Attrition&quot;,
         y = &quot;Total Working Years&quot;) +
    geom_smooth(method = &quot;lm&quot;, se = FALSE, color = &quot;#c44e52&quot;, size = 1.2) +
    theme_bw()</code></pre>
<p><img src="Rscript_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<ul>
<li>Comment: total working years within the company is likely to reduce
attrition rate <br /> <br /></li>
</ul>
<pre class="r"><code>  ggplot(data2, aes(x = Attrition, y = JobInvolvement)) +
    geom_point(fill = &quot;#4c72b0&quot;, alpha = 0.7) +
    labs(title = &quot;Attrition vs Job Involvement&quot;,
         subtitle = &quot;Comparison of JobInvolvement Levels with Job Involvement&quot;,
         x = &quot;Attrition&quot;,
         y = &quot;Job Involvement&quot;) +
    
    geom_smooth(method = &quot;lm&quot;, se = FALSE, color = &quot;darkblue&quot;, size = 1.2)+
    theme_minimal() +
    theme(plot.title = element_text(color = &quot;#222222&quot;, size = 24, face = &quot;bold&quot;),
          plot.subtitle = element_text(color = &quot;#444444&quot;, size = 16),
          axis.title = element_text(color = &quot;#222222&quot;, size = 14),
          axis.text = element_text(color = &quot;#222222&quot;, size = 12),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.border = element_blank(),
          legend.position = &quot;none&quot;,
          plot.background = element_rect(fill = &quot;white&quot;),
          panel.background = element_rect(fill = &quot;white&quot;))</code></pre>
<p><img src="Rscript_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<ul>
<li>Comment: fostering a good job involvement (communication and
relationship around the workplace) could reduce attrition rate. <br />
<br /></li>
</ul>
<pre class="r"><code>  ggplot(data2, aes(x = Attrition, y = MaritalStatus, color = factor(MaritalStatus))) +
    geom_point(size = 3, alpha = 0.5) +
    labs(title = &quot;Attrition vs Marital Status&quot;,
         subtitle = &quot;Scatterplot of Attrition with Marital Status&quot;,
         x = &quot;Attrition&quot;,
         y = &quot;Marital Status&quot;) +
    geom_smooth(method = &quot;lm&quot;, se = FALSE, color = &quot;darkblue&quot;, size = 1.2) +
    theme_bw() +
    scale_color_manual(values = c(&quot;#1F77B4&quot;, &quot;#FF7F0E&quot;, &quot;#2CA02C&quot;),
                       name = &quot;Marital Status&quot;,
                       labels = c(&quot;Divorced&quot;, &quot;Married&quot;, &quot;Single&quot;))</code></pre>
<p><img src="Rscript_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<ul>
<li>Comment: Single workers could be more likely to leave the company
than married and divorced workers <br /> <br /></li>
</ul>
</div>
<div id="fitting-the-model-knn" class="section level2">
<h2>Fitting the model (KNN)</h2>
<ul>
<li><p>Ran the experiment for at least 45000 iterations</p></li>
<li><p>Deep dive into hyper parameter tuning</p></li>
<li><p>Finding out the best hypermarkets to use for future
predictions</p></li>
</ul>
<pre class="r"><code>#Saving a different sets of labels for Navie Bays analysis
#pvalues[9,4]=&quot;Yes&quot;
#pvalues[17,4]=&quot;Yes&quot;
#pvalues[19,4]=&quot;Yes&quot;
#factorsNB=pvalues%&gt;%filter(NB == &quot;Yes&quot;)
#dataZ2=dataZ2[,factorsNB$columns]
#dataZ2=dataZ2[c(2,1,3:20)]
###split data sets into 70% test set and 30% training set


sample_rows=sample(dim(data2)[1],dim(data2)[1]*0.7)
train_sample=data2[sample_rows,]
test_sample=data2[-sample_rows,]


#classify using KNN external validation
classification=knn(train_sample[,1:17],test_sample[,1:17],train_sample$Attrition,k=25,prob=TRUE)
#table(test_sample$Attrition,classification)
cm=confusionMatrix(table(test_sample$Attrition,classification))

probs &lt;- ifelse(classification == &quot;0&quot;, attributes(classification)$prob, 1 - attributes(classification)$prob)
      new_class2 &lt;- ifelse(probs &gt; 0.8, &quot;0&quot;, &quot;1&quot;)
      
a=rocit(score=as.numeric(as.factor(new_class2)),class=as.numeric(test_sample$Attrition))
#cm
#a$AUC
#plot(a)


#######################################KNN
#KNN
#KNN


# Set seed for reproducibility
set.seed(123)

data3 &lt;- data2
sample_rows &lt;- sample(dim(data3)[1], dim(data3)[1] * 0.7)
train_sample &lt;- data3[sample_rows, ]
test_sample &lt;- data3[-sample_rows, ]

# Initialize empty data frame to store AUC values
auc_df_knn &lt;- data.frame(iters = integer(),
                          ks = integer(),
                          thresholds = numeric(),
                          aucs = numeric(),
                          stringsAsFactors = FALSE)

# Loop through 100 iterations
for (i in 1:100) {
  # Randomly sample training data
  sample_rows &lt;- sample(dim(data3)[1], dim(data3)[1] * 0.7)
  train_sample &lt;- data3[sample_rows, ]
  test_sample &lt;- data3[-sample_rows, ]
  
  # Loop through hyperparameters k = 1 to 50
  for (k in 1:50) {
    # Loop through thresholds from 0.1 to 0.9
    for (threshold in seq(0.1, 0.9, 0.1)) {
      # Fit KNN model and make predictions
      knn_fit &lt;- knn(train = train_sample[,1:17], test = test_sample[,1:17], cl = train_sample$Attrition, k = k, prob = TRUE)
      probs2 &lt;- ifelse(knn_fit == &quot;0&quot;, attributes(knn_fit)$prob, 1 - attributes(knn_fit)$prob)
      new_class2 &lt;- ifelse(probs2 &gt; threshold, &quot;0&quot;, &quot;1&quot;)
      # Calculate AUC and add to auc_df_knn
      auc &lt;- rocit(score = as.numeric(as.factor(new_class2)), class = as.numeric(test_sample$Attrition))$AUC
      auc_df_knn &lt;- rbind(auc_df_knn, data.frame(iters = i, ks = k, thresholds = threshold, aucs = auc))
    }
  }
}




avg_auc_knn &lt;- aggregate(aucs ~ ks + thresholds, data = auc_df_knn, FUN = mean)

# Plot average AUC vs. k, with lines for each value of threshold
ggplot(avg_auc_knn, aes(x = ks, y = aucs, group = thresholds, color = thresholds)) +
  geom_line() +
  xlab(&quot;k&quot;) +
  ylab(&quot;Average AUC&quot;) +
  ggtitle(&quot;Average AUC by k and Threshold&quot;) +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))</code></pre>
<p><img src="Rscript_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<pre class="r"><code># Print first 10 rows of auc_df_knn
#head(auc_df_knn, 10)







####knncv
####Doing the same thing with Knn internal cross validation
data3=data2
sample_rows &lt;- sample(dim(data3)[1], dim(data3)[1] * 0.7)
train_sample &lt;- data3[sample_rows, ]
test_sample &lt;- data3[-sample_rows, ]


knncv &lt;- knn.cv(train = train_sample[,1:17], cl = as.numeric(train_sample$Attrition), k =21, prob = TRUE)

probs = ifelse(knncv == &quot;0&quot;,attributes(knncv)$prob, 1- attributes(knncv)$prob)

NewClass = ifelse(probs &gt; 0.9, &quot;0&quot;, &quot;1&quot;)

#table(NewClass,train_sample$Attrition)
#confusionMatrix(table(NewClass,train_sample$Attrition))
#a=rocit(score=as.numeric(as.factor(NewClass)),class=as.numeric(train_sample$Attrition))

#a$AUC
#plot(a)



# Set seed for reproducibility
set.seed(123)

data3 &lt;- data2
sample_rows &lt;- sample(dim(data3)[1], dim(data3)[1] * 0.7)
train_sample &lt;- data3[sample_rows, ]
test_sample &lt;- data3[-sample_rows, ]

# Initialize empty data frame to store AUC values
auc_df &lt;- data.frame(iter = integer(),
                     k = integer(),
                     threshold = numeric(),
                     auc = numeric(),
                     stringsAsFactors = FALSE)

# Loop through 100 iterations
for (i in 1:100) {
  # Randomly sample training data
  sample_rows &lt;- sample(dim(data3)[1], dim(data3)[1] * 0.7)
  train_sample &lt;- data3[sample_rows, ]
  
  # Loop through hyperparameters k = 1 to 50
  for (k in 1:50) {
    # Loop through thresholds from 0.1 to 0.9
    for (threshold in seq(0.1, 0.9, 0.1)) {
      # Fit KNN model and make predictions
      knncv &lt;- knn.cv(train = train_sample[,1:17], cl = as.numeric(train_sample$Attrition), k = k, prob = TRUE)
      probs &lt;- ifelse(knncv == &quot;0&quot;, attributes(knncv)$prob, 1 - attributes(knncv)$prob)
      new_class &lt;- ifelse(probs &gt; threshold, &quot;0&quot;, &quot;1&quot;)
      
      # Calculate AUC and add to auc_df
      auc &lt;- rocit(score = as.numeric(as.factor(new_class)), class = as.numeric(train_sample$Attrition))$AUC
      auc_df &lt;- rbind(auc_df, data.frame(iter = i, k = k, threshold = threshold, auc = auc))
    }
  }
}

# Print first 10 rows of auc_df
#head(auc_df, 10)


# Calculate mean AUC for each value of k
mean_auc &lt;- auc_df %&gt;%
  group_by(k) %&gt;%
  summarise(mean_auc = mean(auc))

# Create ggplot
#ggplot(mean_auc, aes(x = k, y = mean_auc)) +
#  geom_line() +
#  labs(x = &quot;k&quot;, y = &quot;Average AUC&quot;)


# Calculate average AUC for each combination of k and threshold
avg_auc &lt;- aggregate(auc ~ k + threshold, data = auc_df, FUN = mean)

# Plot average AUC vs. threshold, with lines for each value of k
ggplot(avg_auc, aes(x = threshold, y = auc, group = k)) +
  geom_line() +
  xlab(&quot;Threshold&quot;) +
  ylab(&quot;Average AUC&quot;) +
  ggtitle(&quot;Average AUC by Threshold and k&quot;) +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))</code></pre>
<p><img src="Rscript_files/figure-html/unnamed-chunk-12-2.png" width="672" /></p>
<pre class="r"><code># Plot average AUC vs. k, with lines for each value of threshold
ggplot(avg_auc, aes(x = k, y = auc, group = threshold, color = threshold)) +
  geom_line() +
  xlab(&quot;k&quot;) +
  ylab(&quot;Average AUC&quot;) +
  ggtitle(&quot;Average AUC by k and Threshold&quot;) +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))</code></pre>
<p><img src="Rscript_files/figure-html/unnamed-chunk-12-3.png" width="672" /></p>
<ul>
<li>Comment: According to the chart above the best hyper parameters for
Knn and Knn.cv is when threshold equals to 0.8 and 0.9, and when k
equals to 21 and 41 <br /> <br /></li>
</ul>
</div>
<div id="model-selection-navie-bays" class="section level2">
<h2>Model Selection (Navie Bays)</h2>
<ul>
<li><p>Compare results of the model above</p></li>
<li><p>Ran at least 9000 iterations to determine the best results and
the potential of this ML model</p></li>
<li><p>Use these tests to tune the best hyper parameters</p></li>
</ul>
<pre class="r"><code>###################Training on Naviebays, standardized data set with categorical variable

nb_df &lt;- data.frame(iterations = integer(),
                     threshold = numeric(),
                     auc = numeric(),
                     Sen = numeric(),
                     Spe = numeric(),
                     stringsAsFactors = FALSE)

for (i in 1:1000) {
  sample_rows &lt;- sample(dim(data2)[1], dim(data2)[1] * 0.7)
  train_sampleNB3 &lt;- data2[sample_rows, ]
  test_sampleNB3 &lt;- data2[-sample_rows, ]
  
  for (threshold in seq(0.1,0.9,0.1)) {
    nb3model &lt;- naiveBayes(Attrition ~ ., data = train_sampleNB3)
    nb3modelpred &lt;- predict(nb3model, test_sampleNB3[,1:17], type = &quot;raw&quot;)
    nb3modelclass = ifelse(nb3modelpred[,1]&gt;threshold,&quot;0&quot;,&quot;1&quot;)
    cmnb3 &lt;- confusionMatrix(table(nb3modelclass, test_sampleNB3$Attrition))
    a &lt;- rocit(score = as.numeric(as.factor(nb3modelclass)), class = as.numeric(test_sampleNB3$Attrition))$AUC
    nb_df_row &lt;- data.frame(iterations = i, threshold = threshold, auc = a, Sen = cmnb3$byClass[1], Spe = cmnb3$byClass[2])
    nb_df &lt;- rbind(nb_df, nb_df_row)
  }
}

nb_df_mean=nb_df%&gt;%group_by(threshold)%&gt;%summarise(mean=mean(auc))

aggregate(auc ~  threshold,data = nb_df,FUN=mean)</code></pre>
<pre><code>##   threshold       auc
## 1       0.1 0.5987968
## 2       0.2 0.6616905
## 3       0.3 0.7041717
## 4       0.4 0.7255447
## 5       0.5 0.7319338
## 6       0.6 0.7323235
## 7       0.7 0.7244077
## 8       0.8 0.7061661
## 9       0.9 0.6806191</code></pre>
<pre class="r"><code>ggplot(nb_df_mean, aes(x = threshold, y = mean)) +
  geom_line() +ggtitle(&quot;Best Average AUC By Threshold&quot;)+
  xlab(&quot;Threshold&quot;)+ylab(&quot;Average AUC&quot;)</code></pre>
<p><img src="Rscript_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<pre class="r"><code>#testing previous specificity on a single run
sample_rows &lt;- sample(dim(data2)[1], dim(data2)[1] * 0.7)
train_sampleNB3 &lt;- data2[sample_rows, ]
test_sampleNB3 &lt;- data2[-sample_rows, ]
  
nb3model=naiveBayes(Attrition~.,data=train_sampleNB3 )
nb3modelpred=predict(nb3model,test_sampleNB3[,1:17],type = &quot;raw&quot;)
nb3modelclass &lt;- ifelse(nb3modelpred[,1] &gt; 0.6, &quot;0&quot;, &quot;1&quot;)
#confusionMatrix(table(nb3modelclass,test_sampleNB3$Attrition))
#a=rocit(score=as.numeric(as.factor(nb3modelclass)),class=as.numeric(test_sampleNB3$Attrition))

#cm
#a$AUC
#plot(a)</code></pre>
<ul>
<li>Comment: best hyper parameter selection when threshold is 0.6 <br />
<br /></li>
</ul>
</div>
<div id="model-selection-linear-regression" class="section level2">
<h2>Model Selection (Linear Regression)</h2>
<ul>
<li><p>Looking at linear relationship between each variable</p></li>
<li><p>Determine its P value for significance</p></li>
<li><p>Fit the model and find out model’s potential against all models
we chose</p></li>
</ul>
<pre class="r"><code>###################linear regression model

#Using the standardized data from above dataZ
datalm=data3


#split data into training set and test set (linear regression)


fit=glm(Attrition ~.,data=datalm,
         family=binomial)
#summary(fit)

split=0.7
sample_rows &lt;- sample(dim(datalm)[1], dim(datalm)[1] * split)
train_samplelm &lt;- datalm[sample_rows, ]
test_samplelm &lt;- datalm[-sample_rows, ]

lmprob=predict(fit,test_samplelm,type=&quot;response&quot;)
lmprob=ifelse(lmprob&gt;0.3,1,0)
#confusionMatrix(table(lmprob,test_samplelm$Attrition))
#a=rocit(score=as.numeric(as.factor(lmprob)),class=as.numeric(test_samplelm$Attrition))
#a$AUC
#plot(a)

lm_model = data.frame(iteration = integer(),
                      auc = numeric(),
                      threshold = numeric(),
                      Sensitivity = numeric(),
                      Specificity = numeric(),
                      stringsAsFactors = FALSE)
rownames(lm_model)=NULL
for (i in 1:1000) {
  split = 0.7
  sample_rows &lt;- sample(dim(datalm)[1], dim(datalm)[1] * split)
  train_samplelm &lt;- datalm[sample_rows, ]
  test_samplelm &lt;- datalm[-sample_rows, ]
    fit &lt;- glm(Attrition ~   Department + DistanceFromHome + EnvironmentSatisfaction +
                 JobInvolvement + JobSatisfaction + MaritalStatus + OverTime + WorkLifeBalance +
                 YearsAtCompany + YearsInCurrentRole + YearsWithCurrManager,
               data = train_samplelm, family = binomial)
    for (threshold in seq(0.1, 0.6, 0.1)){
    lmprob &lt;- predict(fit, test_samplelm, type = &quot;response&quot;)
    lmprob_class &lt;- ifelse(as.data.frame(lmprob)[,1] &gt; threshold, &quot;1&quot;, &quot;0&quot;)
  cm_lm &lt;- confusionMatrix(table(as.factor(lmprob_class), test_samplelm$Attrition))

    a &lt;- rocit(score = as.numeric(as.factor(lmprob_class)), class = as.numeric(test_samplelm$Attrition))$AUC

    lm_model &lt;- rbind(lm_model, data.frame(iteration = i, auc = a, threshold = threshold,
                       Sensitivity = cm_lm$overall[1], Specificity = cm_lm$overall[2]))
  }
}


lm_model_data=lm_model %&gt;% group_by(threshold) %&gt;% summarise(mean_auc=mean(auc))

ggplot(data = lm_model_data, aes(x = threshold, y = mean_auc)) + 
  geom_line()+ggtitle(&quot;Best Average Result By Threshold&quot;)+ylab(&quot;Average AUC&quot;)+xlab(&quot;Threshold&quot;)</code></pre>
<p><img src="Rscript_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<pre class="r"><code>fit=glm(Attrition ~.,data=datalm,
         family=binomial)
#summary(fit)

split=0.7
sample_rows &lt;- sample(dim(datalm)[1], dim(datalm)[1] * split)
train_samplelm &lt;- datalm[sample_rows, ]
test_samplelm &lt;- datalm[-sample_rows, ]

lmprob=predict(fit,test_samplelm,type=&quot;response&quot;)
lmprob=ifelse(lmprob&gt;0.2,1,0)
#confusionMatrix(table(lmprob,test_samplelm$Attrition))
#a=rocit(score=as.numeric(as.factor(lmprob)),class=as.numeric(test_samplelm$Attrition))
#a$AUC
#plot(a)</code></pre>
<ul>
<li>Comment: selecting threshold 0.2 for best average result.</li>
</ul>
<p><br /> <br /></p>
</div>
<div id="ensemble-models" class="section level2">
<h2>Ensemble Models</h2>
<ul>
<li><p>Selecting the best performing models from the above.</p></li>
<li><p>Ensemble two or more through majority voting system.</p></li>
<li><p>Tune in for the best results and get prepared for new data
prediction.</p></li>
</ul>
<pre class="r"><code>#ensemble knn.cv and naive bayes together through majority vote
data3=data2
sample_rows &lt;- sample(dim(data3)[1], dim(data3)[1] * 0.7)
train_sample &lt;- data3[sample_rows, ]
test_sample &lt;- data3[-sample_rows, ]


knncv &lt;- knn.cv(train = data3[,1:17], cl = as.numeric(data3$Attrition), k =31, prob = TRUE)

probs = ifelse(knncv == &quot;0&quot;,attributes(knncv)$prob, 1- attributes(knncv)$prob)

NewClass = ifelse(probs &gt; 0.9, &quot;0&quot;, &quot;1&quot;)

#table(NewClass,data3$Attrition)
#confusionMatrix(table(NewClass,data3$Attrition))
#a=rocit(score=as.numeric(as.factor(NewClass)),class=as.numeric(data3$Attrition))

#a$AUC
#plot(a)



nb3model=naiveBayes(Attrition~.,data=data3 )
nb3modelpred=predict(nb3model,data3[,1:17],type = &quot;raw&quot;)
nb3modelclass &lt;- ifelse(nb3modelpred[,1] &gt; 0.6, &quot;0&quot;, &quot;1&quot;)
#confusionMatrix(table(nb3modelclass,data3$Attrition))
#a=rocit(score=as.numeric(as.factor(nb3modelclass)),class=as.numeric(data3$Attrition))

#a$AUC
#plot(a)







ensembleknncv &lt;- ifelse(nb3modelclass == 0 &amp; NewClass == 0, 0,
                        ifelse(nb3modelclass == 1 &amp; NewClass == 1, 1, NewClass))


#confusionMatrix(table(ensembleknncv,data3$Attrition))
#a=rocit(score=as.numeric(as.factor(ensembleknncv)),class=as.numeric(data3$Attrition))

#a$AUC
#plot(a)</code></pre>
</div>
<div id="predict-attrition" class="section level2">
<h2>Predict (Attrition)</h2>
<ul>
<li><p>Loading new data set “CaseStudy2CompSet No
Attrition.csv”</p></li>
<li><p>Pre-processing new data sets and standardized all new data sets
with the same scale</p></li>
<li><p>Selecting features that were important during training
sets</p></li>
<li><p>Fit the best model that were selected above and ensemble the
result</p></li>
<li><p>Write out the predictions in “FinalCompData”</p></li>
</ul>
<pre class="r"><code>#Predict Competition Set No Attrition
#Pre processing new data


CompData=read.csv(file = &quot;CaseStudy2CompSet No Attrition.csv&quot;)
CompData$Attrition=0
CompData1 &lt;- CompData %&gt;%
  mutate_if(is.character, as.factor) %&gt;%
  mutate_if(is.factor, ~as.integer(factor(.))-1)

CompData1=predict(preproc,CompData1)

CompData1=CompData1[,Ttest$variable]
#head(CompData1)
#means = apply(data3[, 1:17], 2, mean)
#sds = apply(data3[, 1:17], 2, sd)
#CompData1_scaled &lt;- scale(CompData1, center = unname(means), scale = unname(sds))




#Predict using NB
nb_comp=predict(nb3model,CompData1,type = &quot;raw&quot;)
nb_comp_class &lt;- ifelse(nb_comp[,1] &gt; 0.6, &quot;0&quot;, &quot;1&quot;)

#predict using KNN
knn_comp &lt;- knn(data3[,1:17],CompData1, data3$Attrition, k =41, prob = TRUE)
probs_comp = ifelse(knn_comp == &quot;0&quot;,attributes(knn_comp)$prob, 1- attributes(knn_comp)$prob)
NewClass_comp = ifelse(probs_comp &gt; 0.9, &quot;0&quot;, &quot;1&quot;)


#Ensemble them together
ensemble_comp&lt;- ifelse(nb_comp_class == 0 &amp; NewClass_comp == 0, 0,
                        ifelse(nb_comp_class == 1 &amp; NewClass_comp == 1, 1, NewClass_comp))

CompData$Results=ensemble_comp
FinalCompData=CompData[,c(&quot;ID&quot;,&quot;Results&quot;)]
FinalCompData$Results=ifelse(FinalCompData$Results==0,&quot;No&quot;,&quot;Yes&quot;)
write.csv(FinalCompData,&quot;FinalCompData&quot;, row.names = FALSE)</code></pre>
</div>
<div id="predict-monthlyincome" class="section level2">
<h2>Predict (MonthlyIncome)</h2>
<ul>
<li><p>Loading new data “CaseStudy2CompSet No Salary.csv”</p></li>
<li><p>Similarly process the data like the above</p></li>
<li><p>Selecting features that were important</p></li>
<li><p>Ran the model and write out the predictions in
“Final_lm_data”</p></li>
</ul>
<pre class="r"><code>#linear regression predicting 



fit_pre_glm=glm(MonthlyIncome ~ Age+Department+JobRole+DistanceFromHome+JobInvolvement+JobLevel+
           MaritalStatus+OverTime+StockOptionLevel+TotalWorkingYears+WorkLifeBalance+
           YearsAtCompany+YearsInCurrentRole+YearsWithCurrManager,data=data3)

predictedlm=predict(fit_pre_glm,newdata = data3)
#data3$MonthlyIncome
predictedlm = predictedlm * 6390.264 + 4597.696
residual=data1$MonthlyIncome-predictedlm

#sqrt(mean(residual^2))




data_scaled = data_scaled[, !(colnames(data_scaled) %in% c(&quot;EmployeeCount&quot;, &quot;Over18&quot;, &quot;StandardHours&quot;, &quot;response&quot;))]
fit_pre_glm=lm(MonthlyIncome ~.,data=data_scaled)
#summary(fit_pre_glm)
predictedlm=predict(fit_pre_glm,newdata = data_scaled)
#data3$MonthlyIncome
predictedlm = predictedlm * 6390.264 + 4597.696
residual=data1$MonthlyIncome-predictedlm

#sqrt(mean(residual^2))


#loading competition data
CompData_lm=read.csv(file = &quot;CaseStudy2CompSet No Salary.csv&quot;)

CompData_lm1=CompData_lm %&gt;%
  mutate_if(is.character, as.factor) %&gt;%
  mutate_if(is.factor, ~as.integer(factor(.)) - 1) 

CompData_lm1$MonthlyIncome=1
CompData_lm1=predict(preproc,CompData_lm1)


#CompData_lm &lt;- CompData_lm[, colnames(data_scaled)[-which(colnames(data_scaled) == &quot;MonthlyIncome&quot;)]]

predicted_comp=predict(fit_pre_glm,newdata = CompData_lm1)
predicted_comp=predicted_comp*6390.2643678  + 4597.6959741
CompData_lm$MonthlyIncome=predicted_comp
Final_lm_data=CompData[,c(&quot;ID&quot;,&quot;MonthlyIncome&quot;)]
write.csv(Final_lm_data,&quot;Final_lm_data&quot;, row.names = FALSE)</code></pre>
</div>
<div id="conclusion-recommendation" class="section level2">
<h2>Conclusion &amp; Recommendation</h2>
<ul>
<li><p>With all the analyses and observations above, here are some
recommendations we provide for future:</p></li>
<li><p>Increasing employee monthly income is a potential retention
strategy that should be considered, as it can improve employee
motivation and job satisfaction. Financial incentives are a key factor
in employee retention, and offering higher salaries or bonuses can help
to reduce employee turnover.</p></li>
<li><p>Married workers are less likely to leave their jobs than single
or divorced workers, due to greater financial stability. Hiring more
married workers could be a viable retention strategy for companies
seeking to reduce attrition rates</p></li>
<li><p>While overtime may be necessary in some industries or roles, it
is important to be mindful of the potential negative effects on employee
retention. Higher Overtime level can contribute to higher attrition
rates</p></li>
<li><p>Implementing a longevity plan can be a valuable retention
strategy, as it offers incentives for employees to stay with the company
over the long term. This could include benefits such as paid time off,
flexible schedules, or retirement savings plans.</p></li>
<li><p>Promotion opportunities are a crucial factor in employee
retention, companies that offer clear guidelines for promotion and
reward employees based on merit and performance are more likely to
retain high-performing workers.</p></li>
<li><p>Fostering communication and relationships among employees is a
proven retention strategy that can help to create a positive and
supportive work environment. Companies that encourage team-building
activities, open communication channels, and regular feedback sessions
are more likely to improve employee satisfaction and engagement, which
can lead to lower attrition rates.</p></li>
</ul>
<p><br /> <br /></p>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
